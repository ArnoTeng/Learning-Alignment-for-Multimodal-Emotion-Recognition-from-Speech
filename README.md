# Learning-Alignment-for-Multimodal-Emotion-Recognition-from-Speech
This repo offers the code for building the neural network architecture described in paper :Learning Alignment for Multimodal Emotion Recognition from Speech, and one more thing is that this repo isn't built by the author of the paper, thus I appreciate any feedback of bugs or questions.

Furthermore,the visualization of attention-mechanism,to demonstrate how it make it possible to learn the alignment between multi-modality,has been also discussed and employed at the last section of my work.
